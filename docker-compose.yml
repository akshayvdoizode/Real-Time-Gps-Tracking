# version: '3.8'
# x-spark-common: &spark-common
#     image: bitnami/spark:latest
#     volumes:
#       - ./jobs:/opt/bitnami/spark/jobs
#     command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
#     depends_on:
#       - spark-master
#     environment:
#       SPARK_MODE:Worker
#       SPARK_WORKER_CORES:2
#       SPARK_WORKER_MEMORY:1g
#       SPARK_MASTER_URL:spark://spark-master:7077
#     ports:
#       - "9090:8080"
#       - "7077:7077"
#     networks:
#       - datamasterylab





# services:
#   zookeeper:
#     image: confluentinc/cp-zookeeper:7.4.0
#     hostname: zookeeper
#     container_name: zookeeper
#     ports:
#       - "2181:2181"
#     environment:
#       ZOOKEEPER_CLIENT_PORT: 2181
#       ZOOKEEPER_TICK_TIME: 2000
#     healthcheck:
#       test: [ "CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181" ]
#       interval: 10s
#       timeout: 5s
#       retries: 5
#     networks:
#       - datamasterylab

#   broker:
#     image: confluentinc/cp-kafka:7.4.0
#     hostname: broker
#     container_name: broker
#     depends_on:
#       zookeeper:
#         condition: service_healthy
#     ports:
#       - "9092:9092"
#       - "9101:9101"
#     environment:
#       KAFKA_BROKER_ID: 1
#       KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
#       KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
#       KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
#       KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#       KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
#       KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
#       KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
#       KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
#       KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
#       KAFKA_JMX_PORT: 9101
#       KAFKA_JMX_HOSTNAME: localhost
#     healthcheck:
#       test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
#       interval: 10s
#       timeout: 5s
#       retries: 5
#     networks:
#       - datamasterylab
  
#   spark-master:
#     image: bitnami/spark:latest
#     volumes:
#       - ./jobs:/opt/bitnami/spark/jobs
#     command: bin/spark-class org.apache.spark.deploy.master.Master 
#     ports:
#       - "9090:8080"
#       - "7077:7077"
#     networks:
#       - datamasterylab
#   spark-worker-1:
#     <<: *spark-common
#   spark-worker-2:
#     <<: *spark-common
#   spark-worker-3:
#     <<: *spark-common
#   spark-worker-4:
#     <<: *spark-common
    

# networks:
#  datamasterylab:

#   # postgres:
#   #   image: postgres:latest
#   #   container_name: postgres
#   #   ports:
#   #     - "5432:5432"
#   #   environment:
#   #     POSTGRES_USER: postgres
#   #     POSTGRES_PASSWORD: postgres
#   #     POSTGRES_DB: postgres
#   #   healthcheck:
#   #     test: [ "CMD", "pg_isready", "-U", "postgres" ]
#   #     interval: 10s
#   #     timeout: 5s
#   #     retries: 5

#   # elasticsearch:
#   #   image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
#   #   container_name: es-container
#   #   environment:
#   #     - xpack.security.enabled=false
#   #     - discovery.type=single-node
#   #   ports:
#   #     - 9200:9200

#   # kibana:
#   #   container_name: kb-container
#   #   image: docker.elastic.co/kibana/kibana:8.11.1
#   #   environment:
#   #     - ELASTICSEARCH_HOSTS=http://es-container:9200
#   #   depends_on:
#   #     - elasticsearch
#   #   ports:
#   #     - 5601:5601


x-spark-common: &spark-common
  image: bitnami/spark:latest
  volumes:
    - ./jobs:/opt/bitnami/spark/jobs
  command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  depends_on:
    - spark-master
  environment:
    SPARK_MODE: Worker
    SPARK_WORKER_CORES: 2
    SPARK_WORKER_MEMORY: 1g
    SPARK_MASTER_URL: spark://spark-master:7077
  ports:
    - "9090:8080"
    - "7077:7077"
  networks:
    - datamasterylab

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: [ "CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - datamasterylab

  broker:
    image: confluentinc/cp-kafka:7.4.0
    hostname: broker
    container_name: broker
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9093:9092"  # Changed host port to 9093
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9093  # Updated advertised listeners
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    healthcheck:
      test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - datamasterylab
  
  spark-master:
    image: bitnami/spark:latest
    volumes:
      - ./jobs:/opt/bitnami/spark/jobs
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"
    networks:
      - datamasterylab

  spark-worker-1:
    <<: *spark-common
    ports:
      - "9091:8080"
      - "7078:7077"

  spark-worker-2:
    <<: *spark-common
    ports:
      - "9094:8080"  # Changed to avoid conflict with 9092
      - "7079:7077"

networks:
  datamasterylab:
